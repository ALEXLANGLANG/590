{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet_  as Net\n",
    "from cutout  import Cutout\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "def get_num_correct(pred,labels):\n",
    "    return pred.argmax(dim=1).eq(labels).sum().item()\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hpyerparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "#                                      std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "# train_transform = transforms.Compose([])\n",
    "# if flag_augmetation:\n",
    "#     train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "#     train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
    "# train_transform.transforms.append(transforms.ToTensor())\n",
    "# train_transform.transforms.append(normalize)\n",
    "# if flag_cutout:\n",
    "#     train_transform.transforms.append(Cutout(n_holes = n_holes, length = length))\n",
    "\n",
    "# train_set=torchvision.datasets.CIFAR10(\n",
    "#     root='./data/cifar10',\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=train_transform\n",
    "# )\n",
    "\n",
    "# test_set=torchvision.datasets.CIFAR10(\n",
    "#     root='./data/cifar10',\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=transforms.Compose([transforms.ToTensor(), normalize])\n",
    "# )\n",
    "\n",
    "# GPU check                \n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# if device =='cuda':\n",
    "#     print(\"Run on GPU...\")\n",
    "# else:\n",
    "#     print(\"Run on CPU...\")\n",
    "\n",
    "# # Model Definition  \n",
    "# net = Net(18)\n",
    "# net = net.to(device)\n",
    "\n",
    "# # Test forward pass\n",
    "# data = torch.randn(5,3,32,32)\n",
    "# data = data.to(device)\n",
    "# # Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "# out =  net(data) #Your code here\n",
    "# # Check output shape\n",
    "# assert(out.detach().cpu().numpy().shape == (5,10))\n",
    "# print(\"Forward pass successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(train_set,test_set,lr, depth,model_checkpoint,epochs):\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    train_loader=torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=False, pin_memory=True,num_workers=2)\n",
    "    test_loader=torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, pin_memory=True,num_workers=2)\n",
    "    network= Net(depth).to(device)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 80], gamma=0.2)\n",
    "    \n",
    "    acc_train=[]\n",
    "    acc_test=[]\n",
    "    acc = 0\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        network.train()\n",
    "        count_in = 0\n",
    "        for batch in train_loader: #Get batch\n",
    "            images,labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds=network(images) #pass batch to network\n",
    "            correct = get_num_correct(preds, labels)\n",
    "            loss = criterion(preds,labels) #Calculate loss\n",
    "            loss.backward() #Calculate gradients\n",
    "            optimizer.step() #Update weights\n",
    "            total_correct+=correct\n",
    "        print(\"epoch: \", epoch,  \"total_correct: \", total_correct)\n",
    "        print(\"training accuracy: \", total_correct/len(train_set))\n",
    "        acc_train.append(deepcopy(float(total_correct)/len(train_set)))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct_test=0\n",
    "            for batch_test in test_loader: #Get batch\n",
    "                images_test,labels_test = batch_test\n",
    "                images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "                preds_test=network(images_test) #pass batch to network\n",
    "                correct_test += get_num_correct(preds_test, labels_test)\n",
    "            print(\"testing accuracy: \", correct_test / len(test_set))\n",
    "            if epoch == epochs - 1:\n",
    "                print(correct_test / len(test_set))\n",
    "                acc = correct_test / len(test_set) \n",
    "            acc_test.append(deepcopy(float(correct_test)/len(test_set)))\n",
    "        scheduler.step()\n",
    "        if best_acc < acc:\n",
    "            best_acc = acc\n",
    "            torch.save(network.state_dict(), model_checkpoint)\n",
    "\n",
    "    return (acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(flag_augmetation = False, \n",
    "            flag_cutout = False, \n",
    "            n_holes = 1, \n",
    "            length = 16, \n",
    "            depth = 18,\n",
    "            epochs = 100,\n",
    "            lr = 0.1\n",
    "           ):\n",
    "    model_checkpoint = \"resnet\" + str(depth) \n",
    "    if flag_augmetation:\n",
    "        model_checkpoint += '+'\n",
    "    if flag_cutout:\n",
    "        model_checkpoint += \"cutout\"\n",
    "    model_checkpoint += \".pt\"\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "    train_transform = transforms.Compose([])\n",
    "    if flag_augmetation:\n",
    "        train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "        train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
    "    train_transform.transforms.append(transforms.ToTensor())\n",
    "    train_transform.transforms.append(normalize)\n",
    "    if flag_cutout:\n",
    "        train_transform.transforms.append(Cutout(n_holes = n_holes, length = length))\n",
    "\n",
    "\n",
    "    train_set=torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar10',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transform)\n",
    "\n",
    "    test_set=torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar10',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "    \n",
    "    acc_train,acc_test = train_(train_set,test_set,lr, depth, model_checkpoint, epochs = epochs)\n",
    "    return (acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch:  0 total_correct:  17934\n",
      "training accuracy:  0.35868\n",
      "testing accuracy:  0.4919\n",
      "epoch:  1 total_correct:  28205\n",
      "training accuracy:  0.5641\n",
      "testing accuracy:  0.6224\n",
      "0.6224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.35868, 0.5641], [0.4919, 0.6224])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_test(flag_augmetation = False, \n",
    "            flag_cutout = False, \n",
    "            n_holes = 1, \n",
    "            length = 16, \n",
    "            depth = 18,\n",
    "            epochs = 2,\n",
    "            lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch:  0 total_correct:  18156\n",
      "training accuracy:  0.36312\n",
      "testing accuracy:  0.4859\n",
      "epoch:  1 total_correct:  28414\n",
      "training accuracy:  0.56828\n",
      "testing accuracy:  0.632\n",
      "0.632\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch:  0 total_correct:  14137\n",
      "training accuracy:  0.28274\n",
      "testing accuracy:  0.3772\n",
      "epoch:  1 total_correct:  20721\n",
      "training accuracy:  0.41442\n",
      "testing accuracy:  0.4675\n",
      "0.4675\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch:  0 total_correct:  14776\n",
      "training accuracy:  0.29552\n",
      "testing accuracy:  0.424\n",
      "epoch:  1 total_correct:  24451\n",
      "training accuracy:  0.48902\n",
      "testing accuracy:  0.5479\n",
      "0.5479\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch:  0 total_correct:  11519\n",
      "training accuracy:  0.23038\n",
      "testing accuracy:  0.3247\n",
      "epoch:  1 total_correct:  17293\n",
      "training accuracy:  0.34586\n",
      "testing accuracy:  0.3963\n",
      "0.3963\n",
      "[[0.36312, 0.56828], [0.4859, 0.632], [0.28274, 0.41442], [0.3772, 0.4675], [0.29552, 0.48902], [0.424, 0.5479], [0.23038, 0.34586], [0.3247, 0.3963]]\n"
     ]
    }
   ],
   "source": [
    "list_acc = []\n",
    "for depth in [18,34]:\n",
    "    for flag_cutout in [False, True]:\n",
    "        acc_train,acc_test  = do_test(flag_augmetation = False, \n",
    "                                            flag_cutout = flag_cutout, \n",
    "                                            n_holes = 10, \n",
    "                                            length = 10, \n",
    "                                            depth = depth,\n",
    "                                            epochs = 2,\n",
    "                                          lr = 0.1)\n",
    "        \n",
    "        list_acc.append(acc_train)\n",
    "        list_acc.append(acc_test)\n",
    "print(list_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_acc = pd.DataFrame(list_acc)\n",
    "list_acc.to_csv(\"acc.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 total_correct:  19394\n",
      "training accuracy:  0.38788\n",
      "testing accuracy:  0.5088\n",
      "epoch:  1 total_correct:  29893\n",
      "training accuracy:  0.59786\n",
      "testing accuracy:  0.6038\n",
      "epoch:  2 total_correct:  34235\n",
      "training accuracy:  0.6847\n",
      "testing accuracy:  0.6631\n",
      "epoch:  3 total_correct:  37032\n",
      "training accuracy:  0.74064\n",
      "testing accuracy:  0.7209\n",
      "epoch:  4 total_correct:  39145\n",
      "training accuracy:  0.7829\n",
      "testing accuracy:  0.7548\n",
      "epoch:  5 total_correct:  40576\n",
      "training accuracy:  0.81152\n",
      "testing accuracy:  0.7847\n",
      "epoch:  6 total_correct:  41752\n",
      "training accuracy:  0.83504\n",
      "testing accuracy:  0.7948\n",
      "epoch:  7 total_correct:  42569\n",
      "training accuracy:  0.85138\n",
      "testing accuracy:  0.8134\n",
      "epoch:  8 total_correct:  43238\n",
      "training accuracy:  0.86476\n",
      "testing accuracy:  0.8255\n",
      "epoch:  9 total_correct:  43809\n",
      "training accuracy:  0.87618\n",
      "testing accuracy:  0.8327\n",
      "epoch:  10 total_correct:  44323\n",
      "training accuracy:  0.88646\n",
      "testing accuracy:  0.8356\n",
      "epoch:  11 total_correct:  44845\n",
      "training accuracy:  0.8969\n",
      "testing accuracy:  0.8447\n",
      "epoch:  12 total_correct:  45140\n",
      "training accuracy:  0.9028\n",
      "testing accuracy:  0.8398\n",
      "epoch:  13 total_correct:  45419\n",
      "training accuracy:  0.90838\n",
      "testing accuracy:  0.847\n",
      "epoch:  14 total_correct:  45811\n",
      "training accuracy:  0.91622\n",
      "testing accuracy:  0.8417\n",
      "epoch:  15 total_correct:  46172\n",
      "training accuracy:  0.92344\n",
      "testing accuracy:  0.8547\n",
      "epoch:  16 total_correct:  46549\n",
      "training accuracy:  0.93098\n",
      "testing accuracy:  0.8647\n",
      "epoch:  17 total_correct:  46632\n",
      "training accuracy:  0.93264\n",
      "testing accuracy:  0.8683\n",
      "epoch:  18 total_correct:  47068\n",
      "training accuracy:  0.94136\n",
      "testing accuracy:  0.8738\n",
      "epoch:  19 total_correct:  47050\n",
      "training accuracy:  0.941\n",
      "testing accuracy:  0.8716\n",
      "epoch:  20 total_correct:  47350\n",
      "training accuracy:  0.947\n",
      "testing accuracy:  0.8635\n",
      "epoch:  21 total_correct:  47579\n",
      "training accuracy:  0.95158\n",
      "testing accuracy:  0.8742\n",
      "epoch:  22 total_correct:  47742\n",
      "training accuracy:  0.95484\n",
      "testing accuracy:  0.8735\n",
      "epoch:  23 total_correct:  47979\n",
      "training accuracy:  0.95958\n",
      "testing accuracy:  0.8838\n",
      "epoch:  24 total_correct:  48035\n",
      "training accuracy:  0.9607\n",
      "testing accuracy:  0.8755\n",
      "epoch:  25 total_correct:  48223\n",
      "training accuracy:  0.96446\n",
      "testing accuracy:  0.8841\n",
      "epoch:  26 total_correct:  48420\n",
      "training accuracy:  0.9684\n",
      "testing accuracy:  0.8807\n",
      "epoch:  27 total_correct:  48445\n",
      "training accuracy:  0.9689\n",
      "testing accuracy:  0.8865\n",
      "epoch:  28 total_correct:  48734\n",
      "training accuracy:  0.97468\n",
      "testing accuracy:  0.8881\n",
      "epoch:  29 total_correct:  48784\n",
      "training accuracy:  0.97568\n",
      "testing accuracy:  0.8885\n",
      "epoch:  30 total_correct:  48880\n",
      "training accuracy:  0.9776\n",
      "testing accuracy:  0.8869\n",
      "epoch:  31 total_correct:  49014\n",
      "training accuracy:  0.98028\n",
      "testing accuracy:  0.8865\n",
      "epoch:  32 total_correct:  49069\n",
      "training accuracy:  0.98138\n",
      "testing accuracy:  0.8942\n",
      "epoch:  33 total_correct:  49280\n",
      "training accuracy:  0.9856\n",
      "testing accuracy:  0.892\n",
      "epoch:  34 total_correct:  49257\n",
      "training accuracy:  0.98514\n",
      "testing accuracy:  0.8866\n",
      "epoch:  35 total_correct:  49335\n",
      "training accuracy:  0.9867\n",
      "testing accuracy:  0.8902\n",
      "epoch:  36 total_correct:  49379\n",
      "training accuracy:  0.98758\n",
      "testing accuracy:  0.8883\n",
      "epoch:  37 total_correct:  49502\n",
      "training accuracy:  0.99004\n",
      "testing accuracy:  0.8891\n",
      "epoch:  38 total_correct:  49527\n",
      "training accuracy:  0.99054\n",
      "testing accuracy:  0.8957\n",
      "epoch:  39 total_correct:  49667\n",
      "training accuracy:  0.99334\n",
      "testing accuracy:  0.8936\n",
      "epoch:  40 total_correct:  49673\n",
      "training accuracy:  0.99346\n",
      "testing accuracy:  0.9005\n",
      "epoch:  41 total_correct:  49676\n",
      "training accuracy:  0.99352\n",
      "testing accuracy:  0.8966\n",
      "epoch:  42 total_correct:  49782\n",
      "training accuracy:  0.99564\n",
      "testing accuracy:  0.8994\n",
      "epoch:  43 total_correct:  49809\n",
      "training accuracy:  0.99618\n",
      "testing accuracy:  0.8978\n",
      "epoch:  44 total_correct:  49841\n",
      "training accuracy:  0.99682\n",
      "testing accuracy:  0.902\n",
      "epoch:  45 total_correct:  49841\n",
      "training accuracy:  0.99682\n",
      "testing accuracy:  0.9037\n",
      "epoch:  46 total_correct:  49898\n",
      "training accuracy:  0.99796\n",
      "testing accuracy:  0.9078\n",
      "epoch:  47 total_correct:  49914\n",
      "training accuracy:  0.99828\n",
      "testing accuracy:  0.9083\n",
      "epoch:  48 total_correct:  49922\n",
      "training accuracy:  0.99844\n",
      "testing accuracy:  0.9058\n",
      "epoch:  49 total_correct:  49941\n",
      "training accuracy:  0.99882\n",
      "testing accuracy:  0.9065\n",
      "epoch:  50 total_correct:  49948\n",
      "training accuracy:  0.99896\n",
      "testing accuracy:  0.9045\n",
      "epoch:  51 total_correct:  49947\n",
      "training accuracy:  0.99894\n",
      "testing accuracy:  0.9041\n",
      "epoch:  52 total_correct:  49960\n",
      "training accuracy:  0.9992\n",
      "testing accuracy:  0.9084\n",
      "epoch:  53 total_correct:  49973\n",
      "training accuracy:  0.99946\n",
      "testing accuracy:  0.9097\n",
      "epoch:  54 total_correct:  49976\n",
      "training accuracy:  0.99952\n",
      "testing accuracy:  0.9089\n",
      "epoch:  55 total_correct:  49974\n",
      "training accuracy:  0.99948\n",
      "testing accuracy:  0.9063\n",
      "epoch:  56 total_correct:  49980\n",
      "training accuracy:  0.9996\n",
      "testing accuracy:  0.9073\n",
      "epoch:  57 total_correct:  49989\n",
      "training accuracy:  0.99978\n",
      "testing accuracy:  0.9104\n",
      "epoch:  58 total_correct:  49988\n",
      "training accuracy:  0.99976\n",
      "testing accuracy:  0.9107\n",
      "epoch:  59 total_correct:  49994\n",
      "training accuracy:  0.99988\n",
      "testing accuracy:  0.9116\n",
      "epoch:  60 total_correct:  49988\n",
      "training accuracy:  0.99976\n",
      "testing accuracy:  0.9127\n",
      "epoch:  61 total_correct:  49994\n",
      "training accuracy:  0.99988\n",
      "testing accuracy:  0.9094\n",
      "epoch:  62 total_correct:  49995\n",
      "training accuracy:  0.9999\n",
      "testing accuracy:  0.911\n",
      "epoch:  63 total_correct:  49995\n",
      "training accuracy:  0.9999\n",
      "testing accuracy:  0.9111\n",
      "epoch:  64 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9109\n",
      "epoch:  65 total_correct:  49997\n",
      "training accuracy:  0.99994\n",
      "testing accuracy:  0.9123\n",
      "epoch:  66 total_correct:  49993\n",
      "training accuracy:  0.99986\n",
      "testing accuracy:  0.912\n",
      "epoch:  67 total_correct:  49997\n",
      "training accuracy:  0.99994\n",
      "testing accuracy:  0.9127\n",
      "epoch:  68 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9145\n",
      "epoch:  69 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.913\n",
      "epoch:  70 total_correct:  49996\n",
      "training accuracy:  0.99992\n",
      "testing accuracy:  0.9138\n",
      "epoch:  71 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9115\n",
      "epoch:  72 total_correct:  49997\n",
      "training accuracy:  0.99994\n",
      "testing accuracy:  0.9127\n",
      "epoch:  73 total_correct:  49995\n",
      "training accuracy:  0.9999\n",
      "testing accuracy:  0.9127\n",
      "epoch:  74 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9136\n",
      "epoch:  75 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.913\n",
      "epoch:  76 total_correct:  50000\n",
      "training accuracy:  1.0\n",
      "testing accuracy:  0.9117\n",
      "epoch:  77 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.913\n",
      "epoch:  78 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9128\n",
      "epoch:  79 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9132\n",
      "epoch:  80 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.912\n",
      "epoch:  81 total_correct:  49996\n",
      "training accuracy:  0.99992\n",
      "testing accuracy:  0.9117\n",
      "epoch:  82 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9116\n",
      "epoch:  83 total_correct:  50000\n",
      "training accuracy:  1.0\n",
      "testing accuracy:  0.9116\n",
      "epoch:  84 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9124\n",
      "epoch:  85 total_correct:  50000\n",
      "training accuracy:  1.0\n",
      "testing accuracy:  0.9119\n",
      "epoch:  86 total_correct:  50000\n",
      "training accuracy:  1.0\n",
      "testing accuracy:  0.9117\n",
      "epoch:  87 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9114\n",
      "epoch:  88 total_correct:  49998\n",
      "training accuracy:  0.99996\n",
      "testing accuracy:  0.9113\n",
      "epoch:  89 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9119\n",
      "epoch:  90 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9121\n",
      "epoch:  91 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9114\n",
      "epoch:  92 total_correct:  49999\n",
      "training accuracy:  0.99998\n",
      "testing accuracy:  0.9114\n",
      "epoch:  93 total_correct:  50000\n",
      "training accuracy:  1.0\n",
      "testing accuracy:  0.9122\n"
     ]
    }
   ],
   "source": [
    "train_(train_set,test_set,18,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
